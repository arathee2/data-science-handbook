
# jupyter-notebook

        # display variables without print()
        from IPython.core.interactiveshell import InteractiveShell
        InteractiveShell.ast_node_interactivity = "all"

        # ignore warnings
        import warnings
        warnings.filterwarnings("ignore")

        # display matplotlib without plt.show()
        %matplotlib inline

        # keep track of time
            
            # time module
            import time
            start = time.time()
            ...
            end = time.time()
            elapsed = end - start

            # run cell code one time - use on top of the cell
            %%time
            
            # run a single line of code - use before a line
            %time
        
            # run cell code seven times and return mean time - use on top of the cell
            %%timeit

            # run cell code seven times and return mean time - use before a line
            %time

        # run different kernel
        %R
        rnorm(10)

==============================================================================================================================

# python

        # os commands
        os.getcwd()
        os.chdir(r"")

        # print
        print(*objects, sep=' ', end='\n', file=sys.stdout, flush=False)
        print("Value of x is: {1} and value of y is: {0}".format(y, x))
        print("Value of x is:", x, "and value of y is:", y)

        # operators
        x + y
        x - y
        x * y
        x / y
        x // y                                                  # calculate quotient
        x % y                                                   # calculate remainder, also called modulus
        x ** y                                                  # x raised to power y

        # data types

            # str
            x = 'hello'
            type(x)                                             # return str
            isinstance(x, str)                                  # return True

            # int
            x = 10

            # float
            x = 10.0

            # list
            my_list = [item1, item2, item3]
            my_list = list(item1, item2, item3)

            # tuples
            my_tuple = (item1, item2, item3)
            my_tuple = tuple(item1, item2, item3)

            # sets
            my_set = set()

            # dictionary
            my_dictionary = {'key': 'value', 'key': 'value'}    # key and value can be string, integer or float
            my_dictionary = dict([('key', 'value'), ('key', 'value')])
            my_dictionary = dict(zip([key_list], [value_list]))
            my_dictionary = dict(key='value', key='value')
            my_dictionary.keys()
            my_dictionary.values()
            my_dictionary.items()

        # sorting

            # simple sorting
            sorted(iterable)                                        # iterable can be list, dictionary or other iterable

            # complex sorting
            student_tuples = {
                              '''('name', 'section', 'age')'''
                                 ('john',   'A',      15),
                                 ('jane',   'B',      12),
                                 ('dave',   'B',      10)
            }
            sorted(student_tuples.items(), key=lambda student: student[2], reverse=False)  # sort by age in ascending order

        # if-else condition
        if condition:
            # code
        elif condition:
            # code
        else:
            # code

        # while loop
        while condition:
            # code
            continue                                            # continue to next iteration
            break                                               # exit loop

        # for loop
        for var in seq:
            print(var)
            continue                                            # continue to next iteration
            break                                               # exit loop

        for index, var in enumerate(seq):
            print(str(index) + "-" + str(var))

        for x, y, z in zip(sequence1, sequence2, sequence3):
            print(x, y, z)

        # for loops for dictionaries
        for key, value in dict.items():
            print(str(key) + "-" + str(value))

        # for loops for numpy arrays
        for var in np.nditer(numpy_array):
            print(var)

        global var    # use global variable instead of local variable inside a function
        nonlocal var  # in case of nested functions, access the var present in outer function instead of local function

        # default arguments
        def function_name(x = 2):
            print(x**2)

        # multiple arguments
        def function_name(*args):
        """ print all the parameters """
            for param in args:
                print(param)
        function_name(1, 2, "hi")

        # keyword arguments
        def function_name(**kwargs):
        """ print all the key (parameter name) value (parameter value) pairs passed to the function """
            for key, value in kwargs.items():
                print(str(key) + ":" + str(value))
        function_name(first_name = "Amandeep", last_name = "Rathee")

        map(function, sequence)                       # useful for applying lambda functions to sequences like lists. extract results by list(map())
        filter(function, sequence)                    # use to filter out elements of sequence. access the result using list(filter())
        from functools import reduce
        reduce(function, sequence)                    # reduce list to one number using a function

        # lambda functions
        lambda variables: operations                  # return result of operation
        square = lambda x: x**2                       # return square of x
        maximum = lambda x, y: x if (x > y) else y

        # list comprehension
        squares = [num**2 for num in range(5)]        # produce a list of squares of 0 through 4
        squares = [num**2 for num in range(5) if num % 2 == 0]            # return squares only for even numbers. condition for iterable
        squares = [num**2 if num % 2 == 0 else 0 for num in range(5)]     # return square if number is even else 0. condition for iterator
        pairs = [(num1, num2) for num1 in range(5) for num2 in range(5)]  # return a list of tuples

        # dictionary comprehension
        result = {number: number**2 for number in range(5)}

        # set comprehension
        result = {number for number in range(5)}

        # error handling
        def dummy():
            try:
                root = root(-9)                                          # ValueError is raised, directly jump to except ValueError part
                return root
            except TypeError as t:
                print(t)
            except ValueError as v:
                print(v)                                                 # print v, that is, "Enter a positive integer."

        def root(number):
            if not isinstance(number, int):
                raise TypeError("Enter an integer.")                     # function breaks here and returns TypeError
            elif root < 0:
                raise ValueError("Enter a positive integer.")            # function breaks here and returns ValueError
            else:
                return math.sqrt(number)

        # iterators and iterables
        iterator = iter(iterable)                     # iterable can be any sequence-lists, string, dictonaries etc.
        next(iteration)                               # print the next item in iterable

        list(enumerate(sequence, start = 0))          # return a list of tuples with index and the item of sequence
        list(zip(sequence1, sequence2, sequence3))    # return a list of tuples. each tuple has corresponding items from each sequence

        # load dataframe in chunks
        for df in pd.read_csv("", chunksize = n)      # load "n" rows in chunks. use next(df) to iterate over chunks

        # generators
        generator = (num for num in range(10))        # generator can be iterated over. instead of returning a list at once it returns number as and when required.
        def generator_function(n):
            """ return numbers upto n """
            i = 0
            while i < n
            yield i                                   # generates i and returns as the while loop runs
            i += 1

        # importing data

            # import text file
            file = open("filename.txt", mode = "r")       # open file in read-only mode
            fulltext = file.read()
            firstline = file.readline()                   # read line iteratively
            file.close()
            print(file.closed)                            # check if file is closed

            OR

            with open("filename.txt", "r") as file:
                print(file.readline())

            # import flat file using numpy
            np.loadtxt("filename", delimiter = ",", skiprows = 1, usecols = [1:10], dtype = )
            np.genfromtxt("filename", delimiter = ",", names = True, dtype = None)
            np.recfromcsv("filename")                     # same as genfromtxt() with parameters shown above as default

            # import flat file using pandas
            df = pd.read_csv("filename", nrows = , header = , sep = "", names = ["column names"],
                             comment = ["", ""], na_values = ["", ""], parse_dates = , index_col = )

            array = df.values                             # extract numpy array from dataframe

            # pickled files - python specific
            import pickle

            with open("data.pkl", "rb") as file:          # rb - readonly binary
                      data = pickle.load(file)
            print(data)

            # import excel file
            df = pd.ExcelFile("filename")
            df.sheet_names()  # print sheet names
            df.parse("sheetname", parse_cols = 0, skiprows = 0:2, names = [""])        # extract sheet by specifying sheet name
            df.parse(sheet_index, parse_cols = 0:2, skiprows = [0], names = ["", ""])  # extract sheet by specifying sheet index

==============================================================================================================================

# numpy

    import numpy as np
    
    # creating arrays
        array = np.array([1, 2, 3, 4], dtype = )      # creates a numpy array. for dtype refer this: https://ibb.co/dgP01dv
	np.arange(start, stop, step)                  # similar to seq() in R
        np.linspace(start, stop, num, endpoint=True)  # generate `num` elements between [start, stop]
	np.zeros((5,3))
        np.ones((5,3))
        np.empty((5,3))
	np.full((5,3), num)                           # create a 3x5 array filled with `num`
	np.eye(5)                                     # create a 5x5 identity matrix
	
    # array attributes
    	array.ndim                                    # number of dimensions
        array.shape                                   # shape of array
        array.size                                    # total number of elements in array
        array.itemsize                                # size of each element in memory
	array.nbytes                                  # total size of array in memory (= size times itemsize)
        array.dtype                                   # data type of array

    # indexing and slicing
    
        # indexing
        array1D[0]                                    # returns first element
        array2D[0, -1]                                # returns first row's last element
        array5D[0]                                    # returns first (4D) array
        array5D[0, 1]                                 # returns (3D) array
        array5D[0, 1, 2]                              # returns (2D) array
        array5D[0, 1, 2, 3]                           # returns (1D) array
        array5D[0, 1, 2, 3, 4]                        # returns an element
    
        # slicing
        array1D[start:end:step]                       # negative `step` reverses `start` and `end` argument
        array1D[start:end]                            # omitting step equates to using the default (step=0)
        array1D[start:]                               # omitting end equates to using the default (end = number of elements in the dimension)
	array1D[:end]                                 # omitting start equates to using the default (start=0)
	array1D[:]                                    # omitting all arguments equates to using default start, end and step
	
	# combining indexing and slicing operations
	array2D[start:end:step, index]                # slice and index
	array5D[2:5:2, 2, 2:5:-2, 5]                  # slice and index multidimensional array
	
	# fancy indexing (indexing with list)
	ind = [1, 3, 5]
	array1D[ind]                                  # return copy of array1D with selected indices
	
	ind = np.array([[0, 1], [2,3]])               # index of size 2x2
	array1D[ind]                                  # result always has the shape of the fancy index (2x2 in this case) rather than the array being indexed
	
	row = np.array(0, 1, 2)
	col = np.array(0, 1, 2)
	array2D[row, col]                             # broadcast row and col first and then apply indexing using this broadcasted index
	
	ind = [0, 2]
	array2D[2, ind]                               # combinign simple and fancy indexing
	array2D[2:, ind]                              # combining fancy indexing and slicing
	array2D[boolean_mask, ind]                    # combining fancy indexing and boolean masks (see boolean arrays below)
	
    # views vs copy
        y = array[2:5]                                # return view - changing y will change array
	z = np.copy(array[2:5])                       # return copy - changing z will not effect array
	
    # reshaping arrays
        array = np.zeros((4, 10))
        array.reshape((20, 2))                        # return a copy of the array (copy has the new shape)
	array.reshape((1, 4, 10))                     # create new dimension (= `array[np.newaxis, :, :]`)
	array.reshape((4, 1, 10))                     # create new dimension (= `array[:, np.newaxis, :]`)
	array.reshape((4, 10, 1))                     # create new dimension (= `array[:, :, np.newaxis]`)
        array.resize((20, 2))                         # change the array in-place
	np.tranpose(array)
	
    # concatenate arrays
        np.concatenate((a, b, c), axis=0)             # concatenate array a, b and c along an axis
	np.vstack((a, b, c))                          # vertically stack array a, b and c (= `np.concatenate((a, b, c), axis=0)`)
        np.hstack((a, b, c))                          # horizontally stack array a, b and c (= `np.concatenate((a, b, c), axis=1)`)
	np.dstack((a, b, c))                          # depthwise stack array a, b and c (= `np.concatenate((a, b, c), axis=2)`)
	np.column_stack((a, b))                       # similar to cbind in R
        np.row_stack((a, b))                          # similar to rbind in R
	
    # split arrays
	a, b, c = np.split(array, [3, 5], axis=0)     # split `array` at index 3 and 5
	upper, lower = np.vsplit(array, [3])          # split `array` vertically at index 3 (= `np.split(array, [3], axis=0)`)
	left, right = np.hsplit(array, [3])           # split `array` horizontally at index 3 (= `np.split(array, [3], axis=1)`)
	closer, further = np.dsplit(array, [3])       # split `array` depthwise at index 3 (= `np.split(array, [3], axis=3)`)

    # vectorization
	array * 7                                     # or np.multiply(array, 7). Supports +, -, /, //, ** and %
	array1 * array2                               # or np.multiply(array1, array2). Supports +, -, /, //, ** and %
    
    # broadcasting rules (refer this image to know what is broadcasting: https://ibb.co/cgQFwcG)
	Rule 1: If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its leading (left) side.
	Rule 2: If the shape of the two arrays does not match in any dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.
	Rule 3: If in any dimension the sizes disagree and neither is equal to 1, an error is raised.
	
	# example 1
	    # initial shapes
	    a = (2,3)
	    b = (3)
	    
	    # apply rule 1 to b
	    a = (2,3)
	    b = (1,3)
	    
	    # apply rule 2 to b
	    a = (2,3)
	    b = (2,3)
	
	# example 2
	    # initial shapes
	    a = (3,1)
	    b = (3)
	    
	    # apply rule 1 to b
	    a = (3,1)
	    b = (1,3)
	    
	    # apply rule 2 to a and b
	    a = (3,3)
	    b = (3,3)
	    
	# example 3
	    # initial shapes
	    a = (3,2)
	    b = (3)
	    
	    # apply rule 1 to b
	    a = (3,2)
	    b = (1,3)
	    
	    # applying rule 2 to a and b results in error because shapes do not macth!
	    a = (3,2)
	    b = (3,3)
	    
	    # reshape b from (3) to (3,1) to make broadcasting work
	    a = (3,2)
	    b = (3,1)
    
    # boolean arrays
        array > 3                                     # broadcasts the scalar 3 and returns a boolean ndarray
	array < 3
	array >= 3
	array <= 3
	array != 3
	array == 3
	array1 == array2
	~array <= 0                                   # ~ is the boolean NOT operator
	(array > 0) & (array < 10)                    # combine boolean conditions using the & (AND) or the | (OR) operator
	
	# using boolean arrays for aggregation (see universal functions below)
	np.sum((array > 0) & (array < 10))            # number of positive values less than 10 in the array
	np.any(array > 0)                             # whether or not array has a positive value less than 10
	np.all(array > 0)                             # whether or not all values in array are between 0 (inclusive) and 10 (exclusive)
	
	# using boolean arrays for masking values in arrays
	array[(array > 0) & (array < 10))]            # return array with positive values less than 10

    # universal functions (vectorized functions for arithmetic operations)
	np.abs(array)                                 # or np.absolute(array)
	np.negative(array)
	
	np.add(a, b)                                  # a and b could be scalar or ndarrays
	np.subtract(a, b)
	np.multiply(a, b)
	np.divide(a, b)
	np.floor_divide(a, b)
	np.pow(a, b)
	np.mod(a, b)
	
	np.exp(array)                                 # e ^ bases
	np.power(bases, powers)                       # bases and powers could be scalar or ndarrays
	np.log(array)                                 # natural log
	
	np.sin(array)
	np.cos(array)
	np.tan(array)
	np.arcsin(array)
	np.arccos(array)
	np.arctan(array)
	
        np.sum(array, axis=None)                      # sums up all the elements of array if axis is None or of an arbitrary axis
	np.cumsum(array, axis)                        # other aggregate functions: https://ibb.co/tqWnsR3
	np.prod(array, axis)
	np.cumprod(array, axis)
	np.max(array, axis)
	np.argmax(array, axis)
        np.min(array, axis)
	np.argmin(array, axis)
        np.mean(array, axis)
        np.median(array, axis)
        np.var(array, axis)
        np.std(array, axis)
	np.percentile(array, [10, 40, 90])            # similar to quartile() in R
        np.cov(x, y)
        np.corrcoef(x, y)                             # pearson correlation coefficient
	np.unique(array, axis)

	np.any(array)                                 # whether or not any value is True
	np.all(array)                                 # whether or not all values are True
	
    # the random module
        np.random.seed(4)                             # set seed for random number
        np.random.rand()                              # create random number in [0.0,1.0)
        np.random.randint(low, high, (5,3))           # create a 5x3 ndarray with random numbers in [low, high)
        np.random.random((3, 4))                      # create 3x4 array with random numbers in [0.0,1.0)
        np.random.choice([0,1,2], size, replace, p)   # generate random numbers of size from array with probability p
        np.random.shuffle(array)                      # modify a sequence in-place by shuffling its contents

        # distributions - google numpy distribution functions
        np.random.normal(mean, std, size)
        np.random.binomial(n, p, size)
        np.random.poisson(n, size)
        np.random.exponential(tau, size)

    # sort
    	np.sort(array)                                # return sorted copy of array
	np.argsort(array)                             # return indices of sorted array
	
    # linear regression in numpy
    	slope, intercept = np.polyfit(x, y, 1)        # degree of polynomial is 1 to specify linear regression

    # print options
        from numpy import set_printoptions
        set_printoptions(precision=3)

==============================================================================================================================

# pandas

    import pandas as pd

        # print options
        pd.set_option("display.max_columns", 20)    # set display limit to all columns
        pd.get_options("display.max_rows")
        pd.reset_options("display.max_columns")

        pd.set_option("max_colwidth", 20)

        # os module
        import os
        os.getcwd()
        os.chdir(r"")
        os.listdir(path)
        os.mkdir(path)

        # importing files from current directory
        import glob
        files = glob.glob("*.csv")                         # return list of all csv file names from current working directory

        # read data
        df = pd.read_csv(file_name,
                         sep          =   ,                # character that seprates different values in the file
                         names        = [],                # pass column names explicitly
                         index_col    =   ,                # column index to use as index
                         dtype        =   ,                # refer documentation
                         na_values    =   ,                # list of values to be read as na
                         parse_dates  =   ,                # refer documentation
        )

        df = pd.DataFrame(data        =   ,                # numpy ndarray or python dictionary
                          index       = [],                # list of indices, defaults to arange(n)
                          columns     = [],                # list of column names
        )

        df.shape                                           # return shape as tuple
        df.head(n)                                         # return first "n" rows of df
        df.tail(n)                                         # return last "n" rows of df
        df.dtypes                                          # return data type of each column
        df.describe(percentiles  = None,                   # percentiles to display - range --> [0, 1]
                    include      = 'all',                  # data types to include
                    exclude      = None                    # data types to exclude
        )
        df.info()

        # check missing values
        df.isnull().any()                                  # return True if any of the values is missing
        df.isnull().sum()                                  # check number of missing values
        df.notnull().all()                                 # return True only if no missing values present
        df.dropna(subset  = ["list of columns"],
                  how     = "any/all",
                  thresh  =
        )

        # visualise missing values
        import missingno as msno
        msno.matrix(df)                                # matrix of missing values
        msno.bar(df)                                   # missing value bar chart
        msno.heatmap(df)                               # correlation heatmap - 1 means both variables are missing together; -1 means not missing together even in a single observation
        msno.dendrogram(df)                            # dendogram of variables

        # duplicate rows
        df.duplicated()                                    # boolean ouput
        df.duplicated().sum()                              # return number of duplicate entries
        df.drop_duplicates(keep = "first", inplace = True) # keep first entry and delete rest of the duplicate entries

        # drop column
        df.drop("column_name", axis = 1)

        df.categorical_column.nunique()                    # return number of levels in a categorical variable
        df.categorical_column.value_counts(dropna = False) # similar to table(df$category) in R

        # statistics
        df.corr(method="pearson")                          # return correlation matrix
        df.skew()                                          # return skewness of numeric variables
        df["column_name"].max()
        df["column_name"].mean()
        df["column_name"].mode()
        df["column_name"].std()                            # standard deviation of column
        df.column_name.quantile([0.1, 0.5])                # return quantile value
        df.column_name.cumsum()                            # cumulative sum
        df.column_name.cumprod()                           # cumulative product

        # sample rows or columns
        df.sample(n             =   ,                      # number of rows/columns to sample
                  frac          =   ,                      # either use 'n' or 'frac'
                  replace       = False,                   # sample with ro without replacement
                  random_state  =  4,                      # seed for reproducability
                  axis          =   ,                      # sample either row or columns of dataframe
        )

        # visualisations
        df.hist()
        df.plot(kind="bar", x = , y = )                    # refer documentation
        df.plot(kind='density', subplots=True, layout=(3,3), sharex=False)
        df.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)

        from pandas.tools.plotting import scatter_matrix
        scatter_matrix(df)

        # change columns types
        pd.to_numeric(df.column, errors = "coerce")

        df.column.astype(str)

        df.column.astype("category",
                         categories = ['good', 'excellent'],
                         ordered    = True)


        df.select_dtypes(include    = ["int64"],
                         exclude    = ["float64"])

        # index and column names
        df.index = index_variable                          # index variable must be equal to the number of rows in the dataframe
        df.index.name = "index name"
        df.columns
        df.columns.name

        # hierarchical indexing
        df.set_index(["school", "rollno"], inplace = True)
        df.sort_index()
        df.reset_index(drop=True)                          # drop stops the function to create a new 'index' column after reset
        df.loc["dgv":"dav"]                                # outer indexing (on "school")
        df.loc[1:10]                                       # inner indexing (on "rollno")
        df.loc[(["dgv", "dav"], slice(1, 10)), :]          # colon slicing not permitted inside tuple, instead use slice()
        df.reindex()                                       # conform data frame to new index. arrange rows or add new rows

        # filtering

            # single condition
            df[df.age > 10]
            df[df.age == df.age.max()]
            df[df.age.isin([13, 14, 15, 16, 17, 18, 19])]  # return teenagers

            # multiple conditions
            df[(df.age < 13) & (df.age > 19)]              # return non-teenagers
            df[(df.name == "Aman") | (df.name = "Arjun")]  # return Aman and Arjun both

        df.all()                                           # return True if all the elements are True
        df.any()                                           # return True if any of the elements is True

        # sort dataframe
        df.sort_values(by = ["column_name", "column_name"], ascending = False)

        # rename columns
        df.rename(columns = {"old_column_name":"new_column_name"})  # rename specific columns
        df.columns = ["column1", "column2"]                # rename all columns

        # change columns order
        ordered = ['col_3', 'col_1', 'col_2']
        df = df[ordered]

        # loc, iloc
        df.loc[1:5,:]                                      # print row [1,5]. need to specify the row and column header names
        df.loc[[1, 4, 7], ["column1", "column2"]]
        df.loc[1:10, "column1":"column2"]
        df.loc[age == df.age.max(), :]
        df.iloc[1:10, 2:4]                                 # print row [1, 10). need to specify the row and column indices

        # fill NAs
        df.column_name.fillna(df.column_name.mean(),
                              axis    = "index or columns",
                              method  = "ffil/bfil",
                              limit = 1
        )
        df.fillna(df.mean())
        df.fillna({
            "column_name": value,
            "column_name": value
        })

        df.interpolate(method = "linear")

        # replace values
        replace = {"gender":          {"male": 0, "female": 1},
                   "marital_status":  {"married": 0, "divorced": 1, "single": 2}
        }
        df.replace(replace, inplace = True)
        df.replace({"old_value": "new_value", "old_value": "new_value"})   # mapping
        df.replace(["old_value_list"], ["new_value_list"])                 # mapping

        # apply functions to dataframe
        df.apply(function, axis = 0/1)                     # iterate over columns/rows of dataframe
        df.column_name.apply(lambda x: x**2)               # iterate over values of column
        df.age.apply(np.argmax, axis = 1)                  # max to get max value, np.argmax to get row name with max value

        # group by

            group = df.groupby("categorical_column")       # returns GroupBy object
            group.function()                               # apply function to each group separately

        # group by and summarize

            df.groupby("categorical_column").another_column.function_name()  # count(), min(), max(), sum(), mean()
            df.groupby(["categorical_columns"]).agg({
                "column": [max, min],
                "column": [size, "count"]                  # size and "count" are same. "count" is a numpy function. see numpy functions
            })

            df.groupby("categorical_column").another_column.transform(function_name)  # makes changes to the data inplace

            df.groupby(["categorical_column", boolean_filter]).another_column.function_name()

            # change GroupBy to DataFrame
            df = pd.DataFrame(df.groupby())
            df = df.add_suffix('_count').reset_index()     # or df.add_prefix()

            # set column names after groupby
            df.columns = ["_".join(colname) for colname in df.columns]

        # Melt: wide to long dataframe
        pd.melt(df,
                id_vars    = ["columns_to_keep"],
                value_vars = ["columns to melt"],          # optional, if not provided, function will melt all vars except id_vars
                var_name   = ,                             # new categorical column name
                value_name =                               # new numerical column name
        )                                                  # similar to gather in tidyr

        # Unmelt: long to wide dataframe
        df.pivot_table(index   = ,                         # name of columns not to unmelt
                       columns = ,                         # columns to melt
                       values  =                           # numerical column name
        )                                                  # in case of duplicate values, use aggfunc to aggregate

        # concatenate dataframes - column + column or row + row
        pd.concat(objs         =  [df1, df2],              # make sure the columns names/index is same - reset indexx if needed
                  axis         =  ,                        # 0-index+index, 1-column+column
                  ignore_index = False                     # keep index names
        )

        # merge/join dataframe
        df_1.merge(df2, df3, on = "common_column", how = "inner")

        # stacking and unstacking
        df.stack()
        df.stack.unstack()

        # crosstabs

            # table(category1, catedory2)
            pd.crosstab(df.categorical_column1,
                        df.categorical_column2,            # could pass column lists as well
                        margins   = True,
                        normalize = {0, 1}                 # or {"all", "index", "columns"}. Similar to prop.table() in R
            )

            # group by and summarize
            pd.crosstab(df.categorical_column1,
                        df.categorical_column2
                        values  = df.numerical_column,
                        aggfunc = np.average
            )

        # one-hot encoding
        df_dummy = pd.get_dummies(df,
                                  columns = categorical_columns,     # encodes all object or category type columns
                                  prefix  =
        )

        # subset dataframe based on column names
        pattern = r"column name pattern"
        column_names_bool = list(df.columns.map(lambda x: bool(re.search(pattern, x))))
        column_names = list(df.columns[column_names_bool])
        new_df = df.loc[:, column_names]

        OR

        df.filter(regex='^id.*', axis=1)                   # subset dataframe on column or index names according to given pattern

        # write csv
        df.to_csv("filename.csv", sep = , index = False)

        # remove constant columns
        def drop_constant_columns(dataframe):
            """
            Drops constant value columns of pandas dataframe.
            """
            keep_columns = [column for column in dataframe.columns if len(dataframe[column].unique()) > 1]
            return dataframe[keep_columns].copy()

        df = drop_constant_columns(df)

==============================================================================================================================

# matplotlib

    import matplotlib.pyplot as plt
    
    ## plot types

    	# line plot
        plt.plot(x, y, color='', marker = '', linestyle = '', alpha=0.7)

        # histogram
        plt.hist(x, bins = 30, rwidth = 0.9)           # or pass a list of bin cutoff points

        # bar plot
        plt.bar(x, y)

        # scatter plot
        plt.scatter(x, y, s = "size_variable", c = "color_variable", alpha = )

        # boxplot
        plt.boxplot(x)

        plt.show()                                     # display plot
		plt.clf()                                      # clear plot


    ## object-oriented plotting

        # single plot
        fig  = plt.figure(figsize=(5, 5))
        axes = fig.add_axes([left, bottom, width, height])  # [0.0, 0.0, 1.0, 1.0]
        axes.plot(x, y)
        axes.set_xlabel('', fontsize=10)
        axes.set_ylabel('')
        axes.set_title('')

        # multiple plots
        fig = plt.figure()
        big = fig.add_axes([0, 0, 1, 1])
        big.plot(x, y)

        small = fig.add_axes([0.5, 0.5, 0.3, 0.3])
        small.scatter(x, y)

        # subplots
        fig, axes = subplots(n_row, n_col, figsize=()) # index starts from 1

        axes[(row, col)].plot((x, y))                  # index starts from 0
        axes[(row, col)].plot((x, y))                  # index starts from 0
        axes[(row, col)].plot((x, y))                  # index starts from 0
        axes[(row, col)].set_title('')
        axes[(row, col)].set_suptitle('')

        axes.tight_layout()


    ## customization

    	# themes and styles
        plt.style.use("ggplot")                        # run plt.style.available to check avialble plots
        
    	# figure size
        plt.figure(figsize=(width, height))            # change it before plotting
        
        # labels
        plt.xlabel("x", fontsize=10)                   # see other parameters: https://matplotlib.org/3.1.1/api/text_api.html#matplotlib.text.Text
        plt.ylabel("y")                                # or axes.set_ylabel()
        plt.title("title")
        plt.suptitle("super title")
        
        plt.xticks(arange(2), ("male", "female"))      # customize x-axis ticks
        plt.yticks(rotation = "")                      # customize y-axis ticks
        plt.tick_params()                              # change appearance of ticks, tick labels and gridlines
        plt.tight_layout()                             # pad space between two plots

        # legend
        plt.plot(x, y, color = "blue", label = "male")
        plt.plot(x, y, color = "red", label = "female")
        plt.legend(loc = "upper right")                # or axes.legend()

        # multiple plots using subplot()
        plt.subplot(nrows, ncols, nsubplot)            # all parameters indexed from 1   
        plt.plot(x, y, color = "red")
        plt.title()                                    # each plot can have its own labels and title

        plt.subplot(nrows, ncols, nsubplot)            # activate nth subplot
        plt.plot(a, b, color = "blue")
            
        plt.tight_layout()                             # pad space between two plots

        # zooming and axis
        plt.xlim([xmin, xmax])                         # or axes.set_xlim()
        plt.ylim([ymin, ymax])

        # text and arrows
        plt.annotate("text",
                     xy = (10, 10),                    # text coordinates
                     xytext = (15, 15),                # arrow pointer coordinates
                     arrowprops = {"color": "green"})  # arrow properties

        OR

        plt.text(x, y, s = "show this text at (x,y)")  # display text on x,y point
        plt.grid(True)                                 # to enable the text


    ## images

        image = plt.imread("image.jpg")
        plt.imshow(image, extent = , aspect = )
        plt.axis("off")

        collapsed = image.mean(axis=2)                 # average out all pixel intensities to get one channel color instead of three
        plt.set_cmap("gray")                           # change printing color to black and white
        plt.imshow(collapsed, cmap="gray")
        plt.axis("off")

==============================================================================================================================

# seaborn

        import seaborn as sns

        # colors - for categorical plots
        mycolors = sns.color_palette(["list_of_colors"])         # colors are applied to hue else for category present on x/y axis

        # histogram
        sns.distplot(a            =  df.numeric_column,
                     bins         =  30,
                     hist_kws     =  {"rwidth": 0.9},            # padding between bins
                     color        =  ""
        )

        # count plot
        sns.countplot(x/y         =  "categorical_column",       # x-vertical plot, y-horizontal plot
                      hue         =  "categorical_column",
                      data        =  df,
                      order       =  [],                         # order of variable to plot or list(df.categorical_column.value_counts().index)
                      hue_order   =  [],                         # order of hue variable - google
                      color       =  "",                         # single color for whole plot
                      palette     =  mycolors,                   # or pass dic for hue - {"value": "color", "value": "color"}
                      saturation  =  1.0,                        # saturation of the plot
                      dodge       =  True                        # dodge or stack
        )
        for patch in ax.patches:
            x=patch.get_bbox().get_points()[:,0]
            y=patch.get_bbox().get_points()[1,1]
            ax.annotate("{}%".format(round(100*y/len(df), 1)), xy = (x.mean(), y), ha = "center", va = "bottom")

        # bar plot
        sns.barplot(x             =  "categorical_column",
                    y             =  "numeric_column",           # switch x and y to change plot orientation
                    hue           =  "categorical_column",
                    data          =  df,                         # to sort barplot, use df.sort_values['categorical_column']
                    order         =  ,                           # order of variables as list. example: df.sort_values(by=["categorical_variable"], ascending=False).numeric_variable.tolist()
                    hue_order     =  ,                           # order of hue variable     - google
                    ci            =  "sd",                       # confidence interval for error bar
                    color         =  "",                         # single color for whole plot
                    palette       =  mycolors,                   # or pass dic for hue - {"value": "color", "value": "color"}
                    saturation    =  1.0,                        # saturation of the plot
                    errcolor      =  "",                         # color of error bar
                    errwidth      =  1.5,                        # width of error bar
                    capsize       =  0.1,                        # size of caps of error bar
                    dodge         =  True,                       # dodge or stack
        )

        # violin plot
        sns.violinplot(x          = "categorical_column",        # optional
                       y          = "numeric_column",            # switch x and y to change plot orientation
                       hue        = "categorical_column",
                       data       =  df,
                       order      =  ,                           # order of variable to plot - google
                       hue_order  =  ,                           # order of hue variable     - google
                       inner      =  "quartile",
                       dodge      =  True,                       # dodge or stack
                       color      =  "",                         # single color for whole plot
                       palette    =  mycolors,                   # or pass dic for hue - {"value": "color", "value": "color"}
                       saturation =  1.0,                        # saturation of the plot
        )

        # box plot
        sns.boxplot(x             = "categorical_column",        # optional
                    y             = "numeric_column",            # switch x and y to change plot orientation
                    hue           = "categorical_column",
                    data          = df,
                    order         =  ,                           # order of variable to plot - google
                    hue_order     =  ,                           # order of hue variable     - google
                    color         =  "",                         # single color for whole plot
                    palette       = mycolors,                    # or pass dic for x - {"value": "g", "value": "color"}
                    saturation    = 1.0,                         # saturation of the plot
                    width         = 0.8,                         # width of each box - [0.0, 1.0]
                    dodge         = True,                        # dodge or stack
                    linewidth     = 2,                           # width of outer line of box plot
                    whis          = 1.5                          # points outside of 1.5*IQR from median are outliers
        )

        # scatter plot
        sns.regplot(x             =  "numeric_column",
                    y             =  "numeric_column",
                    data          =  df,
                    fit_reg       =  True,                       # single color for whole plot
                    order         =  1,                          # order of fit
                    x_jitter      =  0,                          # add random noise to x variable
                    y_jitter      =  0,                          # add random noise to y variable
                    color         =  ""                          # color for points
        )

        # density plot
        sns.kdeplot(data          =  ,                           # 1d plot
                    data2         =  ,                           # 2d plot
                    shade         =  True,                       # add color to show varying density
                    vertical      =  False,                      # 1d - change orientation, 2d - no effect
                    gridsize      =  20,                         # number of discrete points in the evaluation grid
                    legend        =  True,                       # 1d - show legend because label not shown on axis, 2d - no effect
                    cumulative    =  False,                      # 1d - cumulative plot, 2d - can't pass this argument
                    cbar          =  False                       # 2d - add color bar
        )

        # heatmap
        mycmap = sns.light_palette(color, reverse=False, as_cmap=True)  # sequential palette from light to color
        mycmap = sns.dark_palette(color, reverse=False, as_cmap=True)   # sequential palette from dark to color
        mycmap = sns.diverging_palette(h_neg=, h_pos=, s=, l=, center="light/dark", as_cmap=True)  # h_neg to light/dark to h_pos

        sns.heatmap(data          =  df.corr(),                  # 2d array data such as a pivot table
                    cmap          =  mycmap,                     # colors of the heatmap
                    center        =  None,                       # value at which to center diverging data
                    annot         =  None,                       # write values in each cell. bool or 2d array
                    fmt           =  ".2f",                      # string formatting for annotations
                    linewidths    =  0.0,                        # line width between cells
                    linecolor     =  "",                         # line color
                    cbar          =  True,                       # display color bar
                    square        =  False,                      # for square sized cells
                    xticklabels   =  "auto",                     # "auto", bool, list-like, or int. See documentation.
                    yticklabels   =  "auto"                      # "auto", bool, list-like, or int. See documentation.
        )

        # pair plot
        g = sns.PairGrid(data, hue = "categorical_column", palette = , vars = [], dropna = True)
        g.map_diag(sns.kdeplot)
        g.map_offdiag(plt.scatter)
        g.add_legend()

        # facet plot - bar, count, box and violin plot
        sns.factorplot(x          =  "categorical_column",
                       y          =  "numeric_column",
                       hue        =  "categorical_column",
                       data       =  df,
                       row        =  "categorical_column",
                       col        =  "categorical_column",
                       kind       =  "bar/count/box/violin",
                       color      =  "",
                       palette    =  mycolors
        )

        # facet plot - histogram and scatter plot
        g = sns.FacetGrid(data, row = "categorical_column", col = "categorical_column", hue = "categorical_column", palette = )
        g.map(plt.hist, "numeric_column")
        g.map(plt.scatter, "numeric_column", "numeric_column")

==============================================================================================================================

# bokeh

        from bokeh.io import output_notebook, show
        from bokeh.plotting import figure

        # glyphs - shapes like markers, lines, wedges and patches. google bokeh glyphs
        plot = figure(plot_width = 400, tools = "pan, box_zoom")  # initialize empty plot
        plot.circle(x = [1,2,3,4,5],            # sequences, numpy arrays, pandas dataframes supported (df.column_name)
                    y = [8,6,5,2,3],            # sequences, numpy arrays, pandas dataframes supported (df.column_name)
                    x_axis_label = "",
                    y_axis_label = ""
                    color = ,
                    size = ,
                    alpha = ,
                    legend = ,                  # label to display on legend when plotting multiple plots on same figure
                    source =                    # in case you are passing source only mention column names in x and y
        )  # draw on plot
        output_file("circle.html")  # plot to be output in a web browser. Use if output_file is imported.
        show(plot)  # display the plot

        # glyphs accept python sequences for every parameter. If single value is provided instead of a sequence, it is used throughout.
        plot.circle([1,2,3,4,5], [8,6,5,2,3], size = [1,2,3,4,5])  # different size for each circle

        # add multiple markers over each other
        plot.x()
        plot.circle()
        plot.triangle()
        show(plot)

        # lines
        plot.line(x = , y = , line_width = )

        # patches - useful to draw geographic regions
        plot.patches(x = [[1,2,3,4], [1,2], [1,2,3]],
                     y = [[7,5,3,6], [5,1], [8,3,6]],
                     color = ["red","blue","green"],
                     line_color = "white"
        )

        # ColumnDataSource - main data frame central to bokeh
        from bokeh.plotting import ColumnDataSource

        cds = ColumnDataSource(df)
        plot.circle(x = "column_name", y = "column_name", source = cds)

    # animations

        # selection appearance
        plot = figure(tools = "box_select, lasso_select")
        plot.circle(x = ,
                    y = ,
                    selection_color = "red",
                    nonselection_fill_alpha = ,
                    nonselection_fill_color =
        )

        # hover appearence
        from bokeh.models import HoverTool

        hover = HoverTool(tooltips = None, mode = "hline")
        plot = figure(tools = [hover, "crosshair"])
        plot.circle(x = ,
                    y = ,
                    hover_color = "red"
        )

        # color mapping
        from bokeh.models import CategoricalColorMapper

        mapper = CategoricalColorMapper(factors = ["male", "female"], palette = ["red", "green"])
        plot.circle(x = "column_name",
                    y = "column_name",
                    source = cds,
                    color = {"field": "gender",
                             "transform: mapper"
                    }
        )

    # layouts

        # row/column layout
        from bokeh.layouts import row, column
        layout = row(p1, p2, p3)     # arrange in row
        layout = column(p1, p2, p3)  # arrange in column
        output_file("layout.html")
        show(layout)

        # nested row/column layout
        column_layout = column(p1, p2)
        nested_layout = row(column_layout, p3, sizing_mode='scale_width')

        # grid layout
        from bokeh.layouts import  gridplot
        layout = gridplot([p1, p2], [p3, None], toolbar_location = None)  # same output as the nested row-column shown above

        # tabbed layout
        from bokeh.models.widgets import Tabs, Panel

        first = Panel(child = row(p1, p2), title = "first")
        second = Panel(child = row(p3), title = "second")

        tabs = Tabs(tabs = [first, second])
        show(tabs)

        # linking plots

    # annotations and guide

        # legend locatiion
        plot = plot.circle()
        plot.legend.location = "top_left"
        plot.legend.background_fill_color = 'lightgray'      # google more legend properties

        # hover tooltips
        from bokeh.models import HoverTool

        hover = HoverTool(tooltips = [
                ("label", "@column_name"),                   # ("length of petal", "@petal_length")
                ("label", "@column_name"),
                ("label", "@column_name")
                ])

        plot = figure(tools = [hover, "pan", "wheel_zoom"])  # or plot.add_tools(hover)
        show(plot)

    # charts

        # histogram
        from bokeh.charts import Histogram  # google bokeh charts
        plot = Histogram(df, "column_name", bins = , color = "categorical_column", title = )
        p.xaxis.axis_label = ""
        p.xaxis.axis_label = ""
        show(plot)

        # boxplot
        from bokeh.charts import BoxPlot
        plot = BoxPlot(df, values = "column_name", label = "categorical_column", color = "categorical_column", title = "")

        # scatter plot
        from bokeh.charts import Scatter
        plot = Scatter(df, x = "column_name", y = "column_name", color/marker = "categorical_column", title = "")

==============================================================================================================================

# regular expressions

        # strings
        string = ""
        string.lower(); string.upper()
        string.strip(); string.lstrip(); string.rstrip()   # strip whitespace
        split_result = string.split(".")                   # return list of substrings separated by "."
        ".".join(split_result)                             # join list items using "."

        "amandeep" + " rathee" == "amandeep rathee"        # concatenate strings
        "yo"*3                                             # return "yoyoyo"

        # quote preference - ' ' < " " < ''' ''' < """ """
        print('What\'s up?') # escaping ' using \'
        print("What's up?")  # ' ' < " "
        print('''What's up "Jim"?''')  # " " < ''' '''
        print("""What'''s''' up?""")  # ''' ''' < """ """

        # regular expressions
        import re
        pattern = r""

        # split
        re.split(pattern, string)                          # split the string at given pattern

        # substitute
        re.sub(pattern, replacement, string)               # replace first occurence of pattern by repl in the string

        # match
        result = re.match(pattern, string)                 # return None is pattern not found at the very start of string
        result.group()                                     # return match result
        result.start()                                     # return start index of the string where pattern was found
        result.end()                                       # return end index of the string where pattern was found

        # search
        result = re.search(pattern, string)                # look for the pattern in the whole string and returns the first occurence
        result.group()

        # findall
        result = re.findall(pattern, string)               # return list all the occurences of patterns present in the string
        result[0:3]

        # finditer
        for match in re.finditer(pattern, string):         # similar to findall but gives freedom to tinker with each match unlike findall
            # do something with the match object found
            print(match.group(0))
            result.append(match.group())

        # extract groups
        # to extract groups, put parenthesis around the part of the pattern that you want to extract
        # group matching can be used with re.match(), re.search() and re.finditer() but not with re.findall()
        result = re.search("([a-zA-Z.0-9]+)(@)([a-zA-Z.]+)", "user.name123@gmail.com")
        result.group(0)                                    # return full match   - equivalent to result.group()
        result.group(1)                                    # return first group  - "user.name123"
        result.group(2)                                    # return second group - "@"
        result.group(3)                                    # return third group  - "gmail.com"

        # working with compile object
        pattern = re.compile(r"")                          # create compile object
        result = pattern.search(string)                    # no need to pass the pattern parameter
        result = pattern.sub(replacement, string)


        # pandas string methods
        s = pd.Series(['a_b_c', 'B', 'C', 'Aaba', ' Baca ', np.nan, 'CABA', 'dog', 'cat'])

        s.str.get(0)                                  # get first element from each string
        s.str[0]                                      # get first element from each string

        s.str.lower()
        s.str.upper()

        s.str.len()

        s.str.strip()
        s.str.lstrip()
        s.str.rstrip()

        s.str.split("_", expand=False)                # split "a_b_c" to [a, b, c]. Refer documentation for more functionality.
        s.str.rsplit("_")                             # same as split but works in reverse direction i.e. from end to start of a string

        s.str.join("_")                               # join on whitespaces using "_"

        s.str.replace(pattern, "custom_string")       # replace pattern with "custom_string"

        pattern = r'[0-9][a-z]'
        s.str.match(pattern, na=False)                # return True if the string is "2N" i.e. exact match
        s.str.contains(pattern, na=False)             # return True if string is "12N4" because "2N" is inside "12N4"
        s.str.find(pattern, start=0, end=None)        # return lowest index where the substring is fully contained between [start:end]

        # recommended: use re inside lambda functions while doing complicated regex tasks
        df.amount.apply(lambda x: x.find(patter))
        df.amount.apply(lambda x: re.findall(pattern, x)[0])  # if [0] is not used result will be [result] instead of `result`

==============================================================================================================================

# web scraping

        from urllib.request import urlretrieve
        urlretrieve("url", "filename.csv")            # save url file to csv

        pd.read_csv("url", sep = )
        pd.read_excel("url", sheetname = None)        # read all sheets of excel file from url as a dictionary with sheet names as keys

==============================================================================================================================

# time series with pandas

        # resampling - change (increase - upsampling or decrease - downsampling) frequency of timeseries data
        # frequencies - T(minute), H(hour), D(day), B(business day), W(week), M(month), Q(quarter), A(year)

        frequency = "2Q"                         # change frequency to half yearly - upsample
        df.resample(frequency).function()        # statistical methods - mean(), sum(), count(), to fill NaN - interpolate()

        # convert variable to date
        df.date_columns = pd.to_datetime(df.date_columns, format = '%m/%d/%Y')
        OR
        df[date_columns] = df[date_columns].apply(lambda date_column: pd.to_datetime(date_column, format = '%m/%d/%Y'), axis=0)

        # date methods
        df.date_column.dt.hour                   # extract hour
        df.date_column.dt.dayofweek              # extract dayofweek
        df.date_column.dt.dayofyear              # extract dayofyear
        df.date_column.dt.weekofyear             # extract weekofyear
        df.date_column.dt.month                  # extract month
        df.date_column.dt.year                   # extract year

        # shift command
        df.shifted = df.date.shift(periods  = ,  # time steps to shift
                                   axis     = 0  # 0-rows, 1-columns
        )
        # visualize time series
        df.column.plot(style = "k.-")      # google styling in matplotlib plot. color(k:black), marker(.:dot), line type(-:solid)

==============================================================================================================================
